"""
embedder.py
"""

from sentence_transformers import SentenceTransformer
import numpy as np
import pickle
import os

class RestaurantEmbedder:
    def __init__(self, model_name='BAAI/bge-m3'):
        print(f"Loading embedding model: {model_name}...")
        self.model = SentenceTransformer(model_name, trust_remote_code=True)
        self.embedding_dim = self.model.get_sentence_embedding_dimension()
        print(f"‚úì Model loaded! Embedding dimension: {self.embedding_dim}")
    
    def extract_cuisine(self, text_input):
        """
        Extract main cuisine from name
        H√†m n√†y s·∫Ω ƒë∆∞·ª£c s·ª≠ d·ª•ng n·∫øu thi·∫øu c·ªôt th·ª±c ƒë∆°n (v√† thi·∫øu qu√° nhi·ªÅu data)
        """
        if not text_input: return ""
        text_lower = str(text_input).lower()    

        keywords = {
            'ph·ªü': 'Vietnamese Pho Noodle',
            'b√∫n': 'Vietnamese Vermicelli',
            'c∆°m': 'Vietnamese Rice',
            'b√°nh m√¨': 'Vietnamese Sandwich',
            'l·∫©u': 'Hotpot',
            'n∆∞·ªõng': 'BBQ Grill',
            'h·∫£i s·∫£n': 'Seafood',
            '·ªëc': 'Snail Seafood',
            'tr√† s·ªØa': 'Milk Tea',
            'cafe': 'Coffee',
            'c√† ph√™': 'Coffee',
            'pizza': 'Pizza Italian',
            'sushi': 'Japanese Sushi'
        }
        
        for key, val in keywords.items():
            if key in text_lower:
                return val
        return "Vietnamese Food"
    
    def _prepare_text(self, row):
        parts = []
        
        # 1. Th√¥ng tin c∆° b·∫£n (QUAN TR·ªåNG NH·∫§T -> ƒê·ªÇ ƒê·∫¶U TI√äN)
        name = row.get('name', '')
        # Nh·∫•n m·∫°nh t√™n qu√°n b·∫±ng c√°ch l·∫∑p l·∫°i
        parts.append(f"Restaurant Name: {name}. {name}") 
        
        # 2. X·ª≠ l√Ω Menu (TƒÇNG TR·ªåNG S·ªê ·ªû ƒê√ÇY)
        menu = row.get('menu_flat', '')
        parts.append(f"Main Menu: {menu}")
        parts.append(f"Signature Dishes: {menu}") 

        # 3. ƒê·ªãa ch·ªâ (√çt quan tr·ªçng h∆°n -> ƒê·ªÉ sau)
        address = row.get('address', '')
        parts.append(f"Address: {address}")
        
        # 4. Cuisine
        category_guess = self.extract_cuisine(name)
        parts.append(f"Category: {category_guess}")

        # 5. Reviews (Quan tr·ªçng nh∆∞ng d√†i, ƒë·ªÉ cu·ªëi ƒë·ªÉ kh√¥ng l√†m lo√£ng Menu)
        review = row.get('reviews_flat', '')
        parts.append(f"Reviews: {review[:2000]}")

        # 6. X·ª≠ l√Ω Scores (T√≠n hi·ªáu ch·∫•t l∆∞·ª£ng)
        scores = row.get('scores', {})
        parts.append(f"Address: {address}")
            
        if scores.get('score_service', 0) >= 8.0:
            parts.append("Excellent service")
        if scores.get('score_space', 0) >= 8.0:
            parts.append("Beautiful space nice view")
        if scores.get('score_price', 0) >= 8.0:
            parts.append("Good price reasonable")

        # N·ªëi t·∫•t c·∫£ l·∫°i th√†nh 1 ƒëo·∫°n vƒÉn
        final_text = ". ".join(parts)
        return final_text
    
    def embeddings(self, df, cache_path='models/embeddings_cache.pkl'):
        """
        H√†m ƒë·ªìng b·ªô th√¥ng minh: D√πng _id c·ªßa MongoDB l√†m kh√≥a ch√≠nh
        """
        # 1. Load Cache c≈©
        cache_data = {}
        if os.path.exists(cache_path):
            with open(cache_path, 'rb') as f:
                cache_data = pickle.load(f)
            print(f"üìÇ Loaded {len(cache_data)} items from cache.")

        # L·∫•y danh s√°ch ID hi·ªán t·∫°i (Chuy·ªÉn sang string ƒë·ªÉ l√†m key)
        # L∆∞u √Ω: DataFrame ph·∫£i c√≥ c·ªôt '_id'
        current_ids = set(df['_id'].astype(str))
        cached_ids = set(cache_data.keys())
        
        cache_changed = False 

        # --- B∆Ø·ªöC 1: X√ìA (CLEANUP) ---
        ids_to_remove = cached_ids - current_ids
        if ids_to_remove:
            print(f"üóëÔ∏è Removing {len(ids_to_remove)} deleted restaurants...")
            for uid in ids_to_remove:
                del cache_data[uid]
            cache_changed = True
        
        # --- B∆Ø·ªöC 2: TH√äM M·ªöI (ADD NEW) ---
        new_texts = []
        new_ids = []
        
        for _, row in df.iterrows():
            raw_id = row.get('_id')
            if raw_id is None: continue
            
            uid = str(raw_id) # Key ph·∫£i l√† string
            
            # N·∫øu qu√°n n√†y ch∆∞a c√≥ trong cache -> Th√™m v√†o danh s√°ch c·∫ßn t√≠nh
            if uid not in cache_data:
                new_ids.append(uid)
                new_texts.append(self._prepare_text(row))
        
        if new_texts:
            print(f"üÜï Embedding {len(new_texts)} new restaurants...")
            new_embeddings = self.model.encode(
                new_texts, 
                batch_size=32, 
                show_progress_bar=True, 
                normalize_embeddings=True
            )
            
            for uid, vector in zip(new_ids, new_embeddings):
                cache_data[uid] = vector
            cache_changed = True

        # --- B∆Ø·ªöC 3: L∆ØU CACHE ---
        if cache_changed:
            os.makedirs(os.path.dirname(cache_path), exist_ok=True)
            with open(cache_path, 'wb') as f:
                pickle.dump(cache_data, f)
            print("üíæ Cache updated successfully!")
        else:
            print("‚ú® Cache is already up-to-date.")

        # --- B∆Ø·ªöC 4: TR·∫¢ V·ªÄ K·∫æT QU·∫¢ ƒê√öNG TH·ª® T·ª∞ (S·ª≠a ƒëo·∫°n n√†y) ---
        ordered_embeddings = []
        for _, row in df.iterrows():
            raw_id = row.get('_id')
            
            # Chuy·ªÉn id sang string ƒë·ªÉ t√¨m trong cache
            uid = str(raw_id) if raw_id is not None else ""
            
            if uid in cache_data:
                ordered_embeddings.append(cache_data[uid])
            else:
                # Fallback (hi·∫øm khi x·∫£y ra)
                ordered_embeddings.append(np.zeros(self.embedding_dim))
                
        return np.array(ordered_embeddings)
    
    def embed_query(self, query: str) -> np.ndarray:
        """
        T·∫°o embedding cho c√¢u truy v·∫•n (query) c·ªßa ng∆∞·ªùi d√πng.
        - D√πng c√πng model BGE-M3
        - Normalize ƒë·ªÉ ph√π h·ª£p v·ªõi cosine similarity
        """
        if not query or not isinstance(query, str):
            return np.zeros(self.embedding_dim, dtype=np.float32)

        # v√≠ d·ª• th√™m keyword "best restaurant", "good food", ...
        cleaned_query = query.strip()

        # Encode (gi·ªëng c·∫•u h√¨nh b·∫°n d√πng cho restaurant embeddings)
        query_emb = self.model.encode(
            cleaned_query,
            normalize_embeddings=True,
            show_progress_bar=False,
            convert_to_numpy=True
        )

        return query_emb.astype(np.float32)