"""
embedder.py
"""

from sentence_transformers import SentenceTransformer
import numpy as np
import pandas as pd
import pickle
import os

class RestaurantEmbedder:
    def __init__(self, model_name='BAAI/bge-m3'):
        print(f"Loading embedding model: {model_name}...")
        self.model = SentenceTransformer(model_name, trust_remote_code=True)
        self.embedding_dim = self.model.get_sentence_embedding_dimension()
        print(f"‚úì Model loaded! Embedding dimension: {self.embedding_dim}")
    
    def extract_cuisine(self, text_input):
        """
        Extract main cuisine from name
        H√†m n√†y s·∫Ω ƒë∆∞·ª£c s·ª≠ d·ª•ng n·∫øu thi·∫øu c·ªôt th·ª±c ƒë∆°n (v√† thi·∫øu qu√° nhi·ªÅu data)
        """
        if not text_input: return ""
        text_lower = str(text_input).lower()    

        keywords = {
            'ph·ªü': 'Vietnamese Pho Noodle',
            'b√∫n': 'Vietnamese Vermicelli',
            'c∆°m': 'Vietnamese Rice',
            'b√°nh m√¨': 'Vietnamese Sandwich',
            'l·∫©u': 'Hotpot',
            'n∆∞·ªõng': 'BBQ Grill',
            'h·∫£i s·∫£n': 'Seafood',
            '·ªëc': 'Snail Seafood',
            'tr√† s·ªØa': 'Milk Tea',
            'cafe': 'Coffee',
            'c√† ph√™': 'Coffee',
            'pizza': 'Pizza Italian',
            'sushi': 'Japanese Sushi'
        }
        
        for key, val in keywords.items():
            if key in text_lower:
                return val
        return "Vietnamese Food"
    
    def _prepare_text(self, row):
        parts = []
        
        # H√†m ph·ª• tr·ª£ l·∫•y gi√° tr·ªã an to√†n
        def get_safe(key, default):
            val = row.get(key, default)
            
            # 1. N·∫øu l√† List ho·∫∑c Dict -> Tr·∫£ v·ªÅ lu√¥n (Kh√¥ng check isna)
            if isinstance(val, (list, dict)):
                return val
            
            # 2. N·∫øu l√† None -> Tr·∫£ v·ªÅ default
            if val is None:
                return default
                
            # 3. Ch·ªâ check pd.isna v·ªõi s·ªë ho·∫∑c chu·ªói
            try:
                if pd.isna(val):
                    return default
            except (ValueError, TypeError):
                # N·∫øu check isna m√† v·∫´n l·ªói (do ki·ªÉu l·∫°) th√¨ coi nh∆∞ n√≥ h·ª£p l·ªá
                return val
                
            return val

        # 1. Th√¥ng tin c∆° b·∫£n
        name = get_safe('name', '')
        address = get_safe('address', '')
        parts.append(f"Name: {name}")
        parts.append(f"Address: {address}")
        
        # 2. Cuisine
        category_guess = self.extract_cuisine(name)
        parts.append(f"Category: {category_guess}")

        # 3. X·ª≠ l√Ω Menu (FIX L·ªñI: Tr√≠ch xu·∫•t t√™n m√≥n ƒÉn t·ª´ Dict)
        menu_items = get_safe('menu', [])
        
        if isinstance(menu_items, list) and menu_items:
            menu_names = []
            for item in menu_items[:30]: # L·∫•y 30 m√≥n ƒë·∫ßu
                if isinstance(item, dict):
                    # N·∫øu l√† object {name: "Ph·ªü", price: 30} -> L·∫•y t√™n
                    m_name = item.get('name', '')
                    if m_name: menu_names.append(str(m_name))
                elif isinstance(item, str):
                    # N·∫øu l√† string "Ph·ªü" -> L·∫•y lu√¥n
                    menu_names.append(item)
                else:
                    # Fallback
                    menu_names.append(str(item))
            
            # Ch·ªâ join khi danh s√°ch kh√¥ng r·ªóng
            if menu_names:
                menu_str = ", ".join(menu_names)
                parts.append(f"Menu: {menu_str}")
                parts.append(f"Signature Dishes: {menu_str}")

        # 4. X·ª≠ l√Ω Reviews (C≈©ng c·∫ßn s·ª≠a t∆∞∆°ng t·ª± ƒë·ªÉ an to√†n)
        reviews = get_safe('reviews', [])
        if isinstance(reviews, list) and reviews:
            review_texts = []
            for r in reviews[:10]:
                if isinstance(r, dict):
                    content = r.get('content', '')
                    if content: review_texts.append(str(content))
                elif isinstance(r, str):
                    review_texts.append(r)
            
            if review_texts:
                full_review = " ".join(review_texts)
                parts.append(f"Reviews: {full_review[:2000]}")

        # 5. Scores (Gi·ªØ nguy√™n)
        scores = get_safe('scores', {})
        if isinstance(scores, dict):
            if scores.get('score_service', 0) >= 8.0: parts.append("Excellent service")
            if scores.get('score_space', 0) >= 8.0: parts.append("Beautiful space nice view")
            if scores.get('score_price', 0) >= 8.0: parts.append("Good price reasonable")

        return ". ".join(parts)
    
    def embeddings(self, df, cache_path='models/embeddings_cache.pkl'):
        """
        H√†m ƒë·ªìng b·ªô th√¥ng minh: D√πng _id c·ªßa MongoDB l√†m kh√≥a ch√≠nh
        """
        # 1. Load Cache c≈©
        cache_data = {}
        if os.path.exists(cache_path):
            with open(cache_path, 'rb') as f:
                cache_data = pickle.load(f)
            print(f"üìÇ Loaded {len(cache_data)} items from cache.")

        # L·∫•y danh s√°ch ID hi·ªán t·∫°i (Chuy·ªÉn sang string ƒë·ªÉ l√†m key)
        # L∆∞u √Ω: DataFrame ph·∫£i c√≥ c·ªôt '_id'
        current_ids = set(df['_id'].astype(str))
        cached_ids = set(cache_data.keys())
        
        cache_changed = False 

        # --- B∆Ø·ªöC 1: X√ìA (CLEANUP) ---
        ids_to_remove = cached_ids - current_ids
        if ids_to_remove:
            print(f"üóëÔ∏è Removing {len(ids_to_remove)} deleted restaurants...")
            for uid in ids_to_remove:
                del cache_data[uid]
            cache_changed = True
        
        # --- B∆Ø·ªöC 2: TH√äM M·ªöI (ADD NEW) ---
        new_texts = []
        new_ids = []
        
        for _, row in df.iterrows():
            raw_id = row.get('_id')
            if raw_id is None: continue
            
            uid = str(raw_id) # Key ph·∫£i l√† string
            
            # N·∫øu qu√°n n√†y ch∆∞a c√≥ trong cache -> Th√™m v√†o danh s√°ch c·∫ßn t√≠nh
            if uid not in cache_data:
                new_ids.append(uid)
                new_texts.append(self._prepare_text(row))
        
        if new_texts:
            print(f"üÜï Embedding {len(new_texts)} new restaurants...")
            new_embeddings = self.model.encode(
                new_texts, 
                batch_size=32, 
                show_progress_bar=True, 
                normalize_embeddings=True
            )
            
            for uid, vector in zip(new_ids, new_embeddings):
                cache_data[uid] = vector
            cache_changed = True

        # --- B∆Ø·ªöC 3: L∆ØU CACHE ---
        if cache_changed:
            os.makedirs(os.path.dirname(cache_path), exist_ok=True)
            with open(cache_path, 'wb') as f:
                pickle.dump(cache_data, f)
            print("üíæ Cache updated successfully!")
        else:
            print("‚ú® Cache is already up-to-date.")

        # --- B∆Ø·ªöC 4: TR·∫¢ V·ªÄ K·∫æT QU·∫¢ ƒê√öNG TH·ª® T·ª∞ (S·ª≠a ƒëo·∫°n n√†y) ---
        ordered_embeddings = []
        for _, row in df.iterrows():
            raw_id = row.get('_id')
            
            # Chuy·ªÉn id sang string ƒë·ªÉ t√¨m trong cache
            uid = str(raw_id) if raw_id is not None else ""
            
            if uid in cache_data:
                ordered_embeddings.append(cache_data[uid])
            else:
                # Fallback (hi·∫øm khi x·∫£y ra)
                ordered_embeddings.append(np.zeros(self.embedding_dim))
                
        return np.array(ordered_embeddings)
    
    def embed_query(self, query: str) -> np.ndarray:
        """
        T·∫°o embedding cho c√¢u truy v·∫•n (query) c·ªßa ng∆∞·ªùi d√πng.
        - D√πng c√πng model BGE-M3
        - Normalize ƒë·ªÉ ph√π h·ª£p v·ªõi cosine similarity
        """
        if not query or not isinstance(query, str):
            return np.zeros(self.embedding_dim, dtype=np.float32)

        # v√≠ d·ª• th√™m keyword "best restaurant", "good food", ...
        cleaned_query = query.strip()

        # Encode (gi·ªëng c·∫•u h√¨nh b·∫°n d√πng cho restaurant embeddings)
        query_emb = self.model.encode(
            cleaned_query,
            normalize_embeddings=True,
            show_progress_bar=False,
            convert_to_numpy=True
        )

        return query_emb.astype(np.float32)